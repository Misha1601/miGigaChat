{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с языковыми моделями﻿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "from GIGACHAT_CREDENTIALS import Scope\n",
    "\n",
    "model = GigaChat(\n",
    "    credentials=Scope,\n",
    "    scope=\"GIGACHAT_API_PERS\",\n",
    "    model=\"GigaChat\",\n",
    "    verify_ssl_certs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Привет, Вася! Чем могу быть полезен?', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 20, 'completion_tokens': 13, 'total_tokens': 33}, 'model_name': 'GigaChat:1.0.26.20', 'x_headers': {'x-request-id': '8dc3fd95-5dfa-43d0-acfd-04657415ec24', 'x-session-id': '9a08f706-9e78-49ce-8bb9-abaf51d8146d', 'x-client-id': None}, 'finish_reason': 'stop'}, id='8dc3fd95-5dfa-43d0-acfd-04657415ec24')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Привет! Меня зовут Вася\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Вас зовут Вася.', additional_kwargs={}, response_metadata={'token_usage': {'prompt_tokens': 65, 'completion_tokens': 8, 'total_tokens': 73}, 'model_name': 'GigaChat:1.0.26.20', 'x_headers': {'x-request-id': 'b0e08607-d171-4f0e-858c-edc85a1c15cc', 'x-session-id': 'c9e671ee-949c-43ef-be2b-ecd16bd50ecb', 'x-client-id': None}, 'finish_reason': 'stop'}, id='b0e08607-d171-4f0e-858c-edc85a1c15cc')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Привет! Меня зовут Вася\"),\n",
    "        AIMessage(\n",
    "            content=\"Здравствуйте, Вася! Я генеративная языковая модель от Сбера. Готова ответить на ваши вопросы.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"Как меня зовут?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Инизиализируйте граф\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# Определите функцию, которая вызывает модель\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Задайте вершину графа\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Добавьте память\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Привет! Меня зовут Вася.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # вывод содержит все сообщения в состоянии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Как меня зовут?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты личный помощник. Старайся как можно лучше помочь пользователю.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke(state)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Привет, Кира! Как я могу помочь тебе сегодня?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Привет! Меня зовут Кира.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты — личный ассистент. Старайся как можно лучше помочь пользователю. Отвечай на все вопросы пользователя на следующем языке: {language}. Не называй своего имени.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    chain = prompt | model\n",
    "    response = chain.invoke(state)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет, Вася!| Вот тебе история о маленьком мальчике по имени Алеша, который жил в небольшом городке на берегу моря.| Его родители были рыбаками, и с самого детства Алеша помогал им на их лодках.| Каждый день он наблюдал за морем, его волнами и штормами, и мечтал узнать, что же скрывается за горизонтом.|\n",
      "\n",
      "Однажды, когда Алеше было всего десять лет, он нашел старую карту сокровищ, спрятанную в сундуке у деда.| На карте была изображена таинственная пещера на одном из островов неподалеку.| Алеша решил во что бы то ни стало найти эту пещеру и отправился в путь на своей маленькой лодке.|\n",
      "\n",
      "Много дней он плыл по морю, преодолевая бурные волны и сильные ветры.| Однажды ночью, после долгого плавания, он увидел свет маяка на острове.| Это был знак, что он почти достиг цели.| Утром Алеша высадился на берег и пошел искать пещеру.| Наконец, он нашел ее - огромную, темную и загадочную.| Внутри пещеры было множество древних артефактов и драгоценностей.| Но самое главное - там находилась старинная книга, которая рассказывала об истории острова и его обитателях.|\n",
      "\n",
      "Алеша вернулся домой героем, привезя с собой не только богатства, но и знания, которые изменили его жизнь навсегда.| С тех пор он стал известен как хранитель тайн и историй своего родного края.| Эта история показывает, что даже самые смелые мечты могут сбываться, если ты готов приложить усилия и не бояться приключений.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Привет! Я Вася. Расскажи историю из 1000 слов\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
